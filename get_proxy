#!/usr/bin/python3
# get_proxy.py
# creater: wangjingzhong
# date: 2017-1-17
import requests
import time
import re
import random

user_agents = [
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1",
    "Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6",
    "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6",
    "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5",
    "Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3",
    "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3",
    "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3",
    "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3",
    "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3",
    "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24",
    "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"
]


def get_random_header():
    # 随机使用user-agent
    headers = {"Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
               "Accept-Encoding": "gzip, deflate, br",
               "Accept-Language": "en,zh-CN;q=0.9,zh;q=0.8",
               "User-Agent": random.choice(user_agents)}  # 随机更换user-agent
    return headers


def get_proxy(web_url, regular, page_num):
    # 获取代理  url:代理网址；regular:正则表达式; page_num:页数。输出：列表。每个列表元素为tuple，包含IP和端口号两个元素
    print("get %s proxies......" % web_url)
    proxies = []
    if page_num == 0:
        r = requests.get(web_url, headers=get_random_header())  # 随机使用header
        r.encoding = 'utf-8'
        proxy_ip = regular.findall(r.text)
        proxies.extend(proxy_ip)
    else:
        for page in range(1, page_num):
            # print("抓取第%d页代理IP" % page)
            url = web_url + str(page)
            print(url)
            time.sleep(3)                                       # 间隔3秒
            r = requests.get(url, headers=get_random_header())  # 随机使用header
            r.encoding = 'utf-8'
            proxy_ip = regular.findall(r.text)
            proxies.extend(proxy_ip)
    return proxies


def get_avai_proxy(all_proxies):
    # 从all_proxies中挑选出可用的proxy。输入：所有代理列表。每条代理有IP和端口号。输出：所有可用代理列表
    print("test proxies......")
    ip_num = len(all_proxies)
    print("共%s条IP需要检测，可能时间较长，请耐心等待" % ip_num)
    # url_own = 'http://ip.chinaz.com/getip.aspx'
    # url = 'http://icanhazip.com/'
    url = 'http://2017.ip138.com/ic.asp'
    p = re.compile(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')               # 提取IP的正则
    r_own = requests.get(url, headers=get_random_header())
    own_ip = p.findall(r_own.text)
    avai_proxy = []                                  # 验证通过的代理
    i = 0
    for ip in all_proxies:
        if i % 10 == 0:
            print("正在处理第%s条数据......" % i)          # 打印处理进度
        i = i + 1
        proxy = {'http': ip[0] + ':' + ip[1]}
        try:
            r = requests.get(url, headers=get_random_header(), proxies=proxy, timeout=4)
            r.encoding = 'utf-8'
            if r.status_code == 200:
                proxy_ip = p.findall(r.text)
                if proxy_ip != own_ip:               # 同自己上网IP比较，如果不一致，则说明该代理可用
                    print(proxy)
                    avai_proxy.append(proxy)
        except:
            pass
    print('availiable proxy result is: ')
    print(avai_proxy)                              # 打印所有可用代理
    return avai_proxy


def get_66_proxy():
    proxyies = []
    for num in range(1, 27):
        url = 'http://www.66ip.cn/areaindex_%s/1.html' % num
        p = re.compile(r'<td>(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})</td><td>(\d+)</td>', re.S)
        proxy = get_proxy(url, p, 0)
        proxyies.extend(proxy)
    return proxyies


def get_kaixin_proxy():
    p = re.compile(r'<td>(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})</td>.*?<td>(\d+)</td>', re.S)
    url = 'http://www.ip181.com/'
    proxy = get_proxy(url, p, 0)
    return proxy


def get_xici_proxy():
    p = re.compile(r'<td class="country">.*?alt="Cn" />.*?</td>.*?<td>(.*?)</td>.*?<td>(.*?)</td>', re.S)
    url = 'http://www.xicidaili.com/nn/'
    proxy = get_proxy(url, p, 3)
    return proxy


def get_xiama_proxy():
    p = re.compile(r'"style1">(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})</td>.*?<td class="style2">(\d+)</td>', re.S)
    url = 'http://www.yun-daili.com/free.asp?page='
    proxy = get_proxy(url, p, 3)
    return proxy


def get_kuaidaili_proxy():
    p = re.compile(r'"IP">(.*?)</td>.*?<td data-title="PORT">(.*?)</td>', re.S)
    url = 'https://www.kuaidaili.com/free/inha/'
    proxy = get_proxy(url, p, 3)
    return proxy


def main():
    all_proxy = []
    kaixin_proxy = get_kaixin_proxy()
    all_proxy.extend(kaixin_proxy)
    xici_proxy = get_xici_proxy()
    all_proxy.extend(xici_proxy)
    xiaoma_proxy = get_xiama_proxy()
    all_proxy.extend(xiaoma_proxy)
    kuaidaili_proxy = get_kuaidaili_proxy()
    all_proxy.extend(kuaidaili_proxy)
    ip66_proxy = get_66_proxy()
    all_proxy.extend(ip66_proxy)
    proxies = set(all_proxy)
    avai_all = get_avai_proxy(proxies)
    return avai_all


main()
